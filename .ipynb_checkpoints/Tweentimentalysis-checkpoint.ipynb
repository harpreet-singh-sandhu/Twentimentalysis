{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <u> Sentiment Analysis On Twitter Posts <u>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 5)"
      ]
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df = pd.read_csv(\"sentiment_100K.csv\", quotechar='\"', encoding= \"ISO-8859-1\")\n",
    "data_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Topic</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>TweetId</th>\n",
       "      <th>TweetDate</th>\n",
       "      <th>TweetText</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Topic Placeholder</td>\n",
       "      <td>negative</td>\n",
       "      <td>2327192251</td>\n",
       "      <td>Thu Jun 25 08:02:11 PDT 2009</td>\n",
       "      <td>@descrovi i miss you</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Topic Placeholder</td>\n",
       "      <td>negative</td>\n",
       "      <td>2327192646</td>\n",
       "      <td>Thu Jun 25 08:02:13 PDT 2009</td>\n",
       "      <td>Was having dinner with parents downstairs in D...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Topic Placeholder</td>\n",
       "      <td>negative</td>\n",
       "      <td>2327193206</td>\n",
       "      <td>Thu Jun 25 08:02:16 PDT 2009</td>\n",
       "      <td>Blah 5am still up  daang I got deep problems</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Topic Placeholder</td>\n",
       "      <td>negative</td>\n",
       "      <td>2327193455</td>\n",
       "      <td>Thu Jun 25 08:02:17 PDT 2009</td>\n",
       "      <td>@jenspeedy I would suggest avoiding 360 Living...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Topic Placeholder</td>\n",
       "      <td>negative</td>\n",
       "      <td>2327193641</td>\n",
       "      <td>Thu Jun 25 08:02:18 PDT 2009</td>\n",
       "      <td>@alexbroun I didn't convince myself I was fat ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Topic Sentiment     TweetId                     TweetDate  \\\n",
       "0  Topic Placeholder  negative  2327192251  Thu Jun 25 08:02:11 PDT 2009   \n",
       "1  Topic Placeholder  negative  2327192646  Thu Jun 25 08:02:13 PDT 2009   \n",
       "2  Topic Placeholder  negative  2327193206  Thu Jun 25 08:02:16 PDT 2009   \n",
       "3  Topic Placeholder  negative  2327193455  Thu Jun 25 08:02:17 PDT 2009   \n",
       "4  Topic Placeholder  negative  2327193641  Thu Jun 25 08:02:18 PDT 2009   \n",
       "\n",
       "                                           TweetText  \n",
       "0                              @descrovi i miss you   \n",
       "1  Was having dinner with parents downstairs in D...  \n",
       "2       Blah 5am still up  daang I got deep problems  \n",
       "3  @jenspeedy I would suggest avoiding 360 Living...  \n",
       "4  @alexbroun I didn't convince myself I was fat ...  "
      ]
     },
     "execution_count": 244,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "negative    5001\n",
       "positive    4999\n",
       "Name: Sentiment, dtype: int64"
      ]
     },
     "execution_count": 245,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df.Sentiment.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Average # words per post: ', 14.397399999999999)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "print(\"Average # words per post: \",np.mean([len(s.split(\" \")) for s in data_df.TweetText]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3000\n",
      "7000\n",
      "10000\n"
     ]
    }
   ],
   "source": [
    "test_set_length = int(0.3*(len(data_df)))\n",
    "training_set_length = int((len(data_df)) - test_set_length)\n",
    "print(test_set_length)\n",
    "print(training_set_length)\n",
    "print(training_set_length +test_set_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('training_set shape: ', (7000, 5))\n",
      "('test_set shape: ', (3000, 5))\n"
     ]
    }
   ],
   "source": [
    "training_set = data_df[0:training_set_length]\n",
    "test_set = data_df[training_set_length:]\n",
    "print(\"training_set shape: \",training_set.shape)\n",
    "print(\"test_set shape: \",test_set.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "397"
      ]
     },
     "execution_count": 249,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del data_df\n",
    "import gc\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from nltk.stem.snowball import SnowballStemmer\n",
    "stemmer = SnowballStemmer(\"english\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def stem_tokens(tokens, stemmer):\n",
    "    stemmed = []\n",
    "    for item in tokens:\n",
    "        stemmed.append(stemmer.stem(item))\n",
    "    return stemmed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re as regex , nltk\n",
    "def tokenize(text):\n",
    "    # remove non letters\n",
    "    text = regex.sub(\"[^a-zA-Z]\", \" \", text)\n",
    "    # tokenize\n",
    "    tokens = nltk.word_tokenize(text)\n",
    "    # stem\n",
    "    stems = stem_tokens(tokens, stemmer)\n",
    "    return stems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer \n",
    "vectorizer = CountVectorizer(\n",
    "    analyzer = 'word',\n",
    "    tokenizer = tokenize, # tokenize is a user defined function declared above\n",
    "    lowercase = True,\n",
    "    stop_words = 'english',\n",
    "    max_features = 200\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "features_matrix = vectorizer.fit_transform(training_set.TweetText.tolist() + test_set.TweetText.tolist())\n",
    "#features_matrix = vectorizer.fit_transform(train_data_df.Text.tolist() + test_data_df.Text.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "features = features_matrix.toarray()\n",
    "#features.shape\n",
    "#del features_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "vocab = vectorizer.get_feature_names()\n",
    "#print(vocab)\n",
    "#del vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#dist = np.sum(features, axis=0)\n",
    "#for tag, count in zip(vocab, dist):\n",
    "#    print count, tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "X_train, X_test, y_train, y_test  = train_test_split(\n",
    "        features, \n",
    "        training_set.Sentiment.tolist() + test_set.Sentiment.tolist(),#data_df.Sentiment\n",
    "        test_size=0.30, \n",
    "        random_state=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "del training_set\n",
    "del test_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "log_model = LogisticRegression()\n",
    "log_model = log_model.fit(X=X_train, y=y_train)\n",
    "y_pred = log_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "   negative       0.74      0.66      0.69      1494\n",
      "   positive       0.69      0.77      0.73      1506\n",
      "\n",
      "avg / total       0.71      0.71      0.71      3000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "gnb = GaussianNB()\n",
    "NB_model = gnb.fit(X=X_train, y=y_train)\n",
    "NB_predictions = NB_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "   negative       0.79      0.42      0.55      1494\n",
      "   positive       0.61      0.89      0.72      1506\n",
      "\n",
      "avg / total       0.70      0.66      0.63      3000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, NB_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "svm_clf = SVC()\n",
    "svm_model = svm_clf.fit(X=X_train, y=y_train) \n",
    "svm_predictions = svm_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "   negative       0.78      0.55      0.65      1494\n",
      "   positive       0.66      0.85      0.74      1506\n",
      "\n",
      "avg / total       0.72      0.70      0.69      3000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, svm_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import tree\n",
    "clf = tree.DecisionTreeClassifier()\n",
    "clf = clf.fit(X_train, y_train)\n",
    "clf_predictions = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "   negative       0.68      0.68      0.68      1494\n",
      "   positive       0.68      0.68      0.68      1506\n",
      "\n",
      "avg / total       0.68      0.68      0.68      3000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, clf_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "clf = RandomForestClassifier(n_estimators=40)\n",
    "clf = clf.fit(X_train, y_train)\n",
    "clf_predictions = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "   negative       0.71      0.69      0.70      1494\n",
      "   positive       0.70      0.73      0.71      1506\n",
      "\n",
      "avg / total       0.71      0.71      0.71      3000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, clf_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import BernoulliNB\n",
    "clf = BernoulliNB()\n",
    "clf.fit(X_train, y_train)\n",
    "clf_predictions = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "   negative       0.76      0.61      0.68      1494\n",
      "   positive       0.68      0.81      0.74      1506\n",
      "\n",
      "avg / total       0.72      0.71      0.71      3000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, clf_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "clf = AdaBoostClassifier()\n",
    "clf.fit(X_train, y_train)\n",
    "clf_predictions = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "   negative       0.77      0.60      0.67      1494\n",
      "   positive       0.67      0.82      0.74      1506\n",
      "\n",
      "avg / total       0.72      0.71      0.71      3000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, clf_predictions))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
