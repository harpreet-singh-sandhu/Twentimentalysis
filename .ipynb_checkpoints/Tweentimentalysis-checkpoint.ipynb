{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <u> Sentiment Analysis On Twitter Posts <u>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing The Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1600000, 5)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df = pd.read_csv(\"sentiment.csv\", quotechar='\"', encoding= \"ISO-8859-1\")\n",
    "data_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1600000, 2)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df=data_df.drop('Topic',1)\n",
    "data_df=data_df.drop('TweetId',1)\n",
    "data_df=data_df.drop('TweetDate',1)\n",
    "data_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data_df.columns = [\"Sentiment\",\"TweetText\"]\n",
    "positive_sentiment = data_df[data_df['Sentiment']=='positive']\n",
    "negative_sentiment = data_df[data_df['Sentiment']=='negative']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200000, 2)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val = 100000\n",
    "frames = [positive_sentiment[:val], negative_sentiment[:val]]\n",
    "data_df = pd.concat(frames)\n",
    "data_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <u>Exploring the Data<u>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>TweetText</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>800000</th>\n",
       "      <td>positive</td>\n",
       "      <td>I LOVE @Health4UandPets u guys r the best!!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>800001</th>\n",
       "      <td>positive</td>\n",
       "      <td>im meeting up with one of my besties tonight! ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>800002</th>\n",
       "      <td>positive</td>\n",
       "      <td>@DaRealSunisaKim Thanks for the Twitter add, S...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>800003</th>\n",
       "      <td>positive</td>\n",
       "      <td>Being sick can be really cheap when it hurts t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>800004</th>\n",
       "      <td>positive</td>\n",
       "      <td>@LovesBrooklyn2 he has that effect on everyone</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Sentiment                                          TweetText\n",
       "800000  positive       I LOVE @Health4UandPets u guys r the best!! \n",
       "800001  positive  im meeting up with one of my besties tonight! ...\n",
       "800002  positive  @DaRealSunisaKim Thanks for the Twitter add, S...\n",
       "800003  positive  Being sick can be really cheap when it hurts t...\n",
       "800004  positive    @LovesBrooklyn2 he has that effect on everyone "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "positive    100000\n",
       "negative    100000\n",
       "Name: Sentiment, dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df.Sentiment.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average # words per post:  14.379525\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "print(\"Average # words per post: \",np.mean([len(s.split(\" \")) for s in data_df.TweetText]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000\n",
      "140000\n",
      "200000\n"
     ]
    }
   ],
   "source": [
    "test_set_length = int(0.3*(len(data_df)))\n",
    "training_set_length = int((len(data_df)) - test_set_length)\n",
    "print(test_set_length)\n",
    "print(training_set_length)\n",
    "print(training_set_length +test_set_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training_set shape:  (140000, 2)\n",
      "test_set shape:  (60000, 2)\n"
     ]
    }
   ],
   "source": [
    "training_set = data_df[0:training_set_length]\n",
    "test_set = data_df[training_set_length:]\n",
    "print(\"training_set shape: \",training_set.shape)\n",
    "print(\"test_set shape: \",test_set.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "del data_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <u> Tokenizing and Stemming <u>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Stemming is the process for reducing derived words to their base or root form \n",
    "##### Ex: \n",
    " - \"fishing\", \"fished\", and \"fisher\" == fish\n",
    " - \"argue\", \"argued\", \"argues\", \"arguing\" == argu\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from nltk.stem.snowball import SnowballStemmer\n",
    "stemmer = SnowballStemmer(\"english\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def stem_tokens(tokens, stemmer):\n",
    "    stemmed = []\n",
    "    for item in tokens:\n",
    "        stemmed.append(stemmer.stem(item))\n",
    "    return stemmed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re as regex , nltk\n",
    "def tokenize(text):\n",
    "    # remove non letters\n",
    "    text = regex.sub(\"[^a-zA-Z]\", \" \", text)\n",
    "    # tokenize\n",
    "    tokens = nltk.word_tokenize(text)\n",
    "    # stem\n",
    "    stems = stem_tokens(tokens, stemmer)\n",
    "    return stems"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <u> Feature Extraction <u>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|       |Love |Guns | Taylor swift| Sick |Lonely | Excited | bed |Thanks |\n",
    "|-------|:---:|:---:|:-----------:|:----:|:-----:|:-------:|:---:|:-----:|     \n",
    "|tweet 1| 3   | 0   | 1           |0     |0      | 1       |1    |2      |\n",
    "|tweet 2| 0   | 1   |0            |2     | 1     |1        |0    |0      |\n",
    "|tweet 3| 4   | 0   |0            | 1    |  0    | 0       | 0   | 0     |\n",
    "|tweet 4| 0   | 1   |0            |0     |2      |1        |2    |0      |\n",
    "|tweet 5|0    |0    |2            |1     |1      |2        |0    |0      |\n",
    "|tweet 6|1    |0    |0            |0     |0      |0        |0    |0      |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer \n",
    "vectorizer = CountVectorizer(\n",
    "    analyzer = 'word',\n",
    "    tokenizer = tokenize, # tokenize is a user defined function declared above\n",
    "    lowercase = True,\n",
    "    stop_words = 'english',\n",
    "    #max_features = 200\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200000, 118734)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_matrix = vectorizer.fit_transform(training_set.TweetText.tolist() + test_set.TweetText.tolist())\n",
    "features_matrix.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### When we run Feature Extraction on 1.6 million tweets we get  <u> 533,386 features <u> (distinct words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <u> Training and Testing <u>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "X_train, X_test, y_train, y_test  = train_test_split(\n",
    "        features_matrix, \n",
    "        training_set.Sentiment.tolist() + test_set.Sentiment.tolist(),\n",
    "        test_size=0.30, \n",
    "        random_state=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "del training_set\n",
    "del test_set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <u> Logistic Regression <u>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "log_model = LogisticRegression()\n",
    "log_model = log_model.fit(X=X_train, y=y_train)\n",
    "y_pred = log_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "   negative       0.77      0.75      0.76     29865\n",
      "   positive       0.76      0.78      0.77     30135\n",
      "\n",
      "avg / total       0.76      0.76      0.76     60000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, y_pred))\n",
    "del log_model\n",
    "del y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### <u>Decision Tree<u>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import tree\n",
    "clf = tree.DecisionTreeClassifier()\n",
    "clf = clf.fit(X_train, y_train)\n",
    "clf_predictions = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "   negative       0.69      0.72      0.70       29865\n",
      "   positive       0.71      0.68      0.70       30135\n",
      "\n",
      "avg / total       0.70      0.70      0.70       60000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, clf_predictions))\n",
    "del clf\n",
    "del clf_predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <u> Random Forest <u>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "clf = RandomForestClassifier(n_estimators=40)\n",
    "clf = clf.fit(X_train, y_train)\n",
    "clf_predictions = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "   negative       0.73      0.78      0.75       29865\n",
      "   positive       0.77      0.72      0.74       30135\n",
      "\n",
      "avg / total       0.75      0.75      0.75       60000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, clf_predictions))\n",
    "del clf\n",
    "del clf_predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <u> Bernoulli Naive bayes<u>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import BernoulliNB\n",
    "clf = BernoulliNB()\n",
    "clf.fit(X_train, y_train)\n",
    "clf_predictions = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "   negative       0.74      0.80      0.77       29865\n",
      "   positive       0.78      0.72      0.75       30135\n",
      "\n",
      "avg / total       0.76      0.76      0.76       60000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, clf_predictions))\n",
    "del clf\n",
    "del clf_predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <u> ADA Boost <u>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "clf = AdaBoostClassifier()\n",
    "clf.fit(X_train, y_train)\n",
    "clf_predictions = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "   negative       0.77      0.50      0.61       29865\n",
      "   positive       0.63      0.85      0.73       30135\n",
      "\n",
      "avg / total       0.70      0.68      0.67       60000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, clf_predictions))\n",
    "del clf\n",
    "del clf_predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results obtained while running the program on 1,600,000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|Classifier | F1score |\n",
    "|-----------|:-------:|\n",
    "|Logistic regression| 78% |\n",
    "|Bernoulli NB | 76% |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <u> Future Work <u>\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.  Experiment with feature extraction\n",
    "        - try bigrams, trigrams etc.\n",
    "        - tf (term frequency), and tf-idf (Term Frequency times Inverse Document Frequency)\n",
    "#### 2.  Try feature Selection (consider only Adjectives, ignore prepositions and other junk words)\n",
    "#### 3.  A more Thorough Tuning  of the Classifier parameters\n",
    "#### 4.  Try other classifiers"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
